# Spatial-Semantic Mamba (SS-Mamba)

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch 2.0+](https://img.shields.io/badge/pytorch-2.0+-red.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Official implementation of **"Spatial-Semantic Mamba: Preserving 2D Structure and Meaningful Sequencing for Enhanced Computational Pathology"**

## Paper
ðŸ“„ **Spatial-Semantic Mamba: Preserving 2D Structure and Meaningful Sequencing for Enhanced Computational Pathology**

- PDF: [`Spatial_Semantic_Mamba.pdf`](./Spatial_Semantic_Mamba.pdf)

> This work was developed as a graduate-level research project and is currently an unpublished manuscript / preprint.



## Overview

SS-Mamba is a novel framework for Whole Slide Image (WSI) classification that addresses two critical limitations in current computational pathology methods:

1. **Spatial Discrepancy**: Standard methods flatten 2D patches into 1D sequences, destroying spatial relationships
2. **Random Patch Ordering**: MIL frameworks process patches in arbitrary order, ignoring semantic relationships

Our approach introduces:
- **2D-SSM Backbone**: Bidirectional scanning along horizontal and vertical axes
- **Semantic Pre-ordering**: Parameter-free ordering based on feature similarity
- **BiMamba Aggregator**: Bidirectional Mamba for MIL aggregation


## Project Structure

```
SS-Mamba/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml              # Configuration file
â”œâ”€â”€ ss_mamba/                    # Main package
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ ss_mamba.py          # Full SS-Mamba model
â”‚   â”‚   â”œâ”€â”€ backbone/
â”‚   â”‚   â”‚   â””â”€â”€ mamba_2d.py      # 2D-SSM backbone
â”‚   â”‚   â”œâ”€â”€ ordering/
â”‚   â”‚   â”‚   â””â”€â”€ semantic_ordering.py
â”‚   â”‚   â””â”€â”€ aggregator/
â”‚   â”‚       â””â”€â”€ bimamba_mil.py   # BiMamba aggregator
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ wsi_dataset.py       # WSI dataset class
â”‚   â”‚   â”œâ”€â”€ preprocessing.py     # Patch extraction
â”‚   â”‚   â””â”€â”€ transforms.py        # Augmentations
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ metrics.py           # Evaluation metrics
â”‚       â”œâ”€â”€ logger.py            # Logging utilities
â”‚       â””â”€â”€ visualization.py     # Visualization tools
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ train.py                 # Training script
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation script
â”‚   â””â”€â”€ extract_features.py      # Feature extraction
â””â”€â”€ scripts/
    â”œâ”€â”€ run_experiment.sh        # Run single experiment
    â””â”€â”€ run_all_datasets.sh      # Run all experiments
```


### 1. Data Preparation

Download datasets and organize as follows:

```
data/
â”œâ”€â”€ camelyon16/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ slides/              # .tif files
â”‚   â”‚   â””â”€â”€ labels.csv
â”‚   â””â”€â”€ test/
â”œâ”€â”€ tcga_brca/
â”‚   â”œâ”€â”€ slides/
â”‚   â””â”€â”€ labels.csv
â””â”€â”€ bracs/
    â”œâ”€â”€ slides/
    â””â”€â”€ labels.csv
```

### 2. Patch Extraction

```bash
python tools/extract_features.py \
    --data_path /path/to/slides \
    --output_path /path/to/patches \
    --patch_size 256 \
    --magnification 20
```

### 3. Training

```bash
# Camelyon16 (binary classification)
python tools/train.py \
    --dataset camelyon16 \
    --data_path /path/to/data \
    --num_classes 2 \
    --epochs 100

# TCGA-BRCA (4-class classification)
python tools/train.py \
    --dataset tcga_brca \
    --data_path /path/to/data \
    --num_classes 4 \
    --epochs 100

# BRACS (7-class classification)
python tools/train.py \
    --dataset bracs \
    --data_path /path/to/data \
    --num_classes 7 \
    --epochs 150
```

Or use shell scripts:

```bash
bash scripts/run_experiment.sh camelyon16
bash scripts/run_all_datasets.sh
```

### 4. Evaluation

```bash
python tools/evaluate.py \
    --dataset camelyon16 \
    --checkpoint /path/to/checkpoint.pth \
    --data_path /path/to/data
```

## Configuration

Edit `configs/config.yaml` for custom settings:

```yaml
model:
  hidden_dim: 512
  num_layers: 2
  dropout: 0.25

ordering:
  lambda_spatial: 0.5
  sigma: 100

training:
  lr: 0.0002
  weight_decay: 0.05
  epochs: 100
  batch_size: 1
```

## Datasets

| Dataset | WSIs | Classes | Task | Link |
|---------|------|---------|------|------|
| Camelyon16 | 399 | 2 | Metastasis Detection | [Link](https://camelyon16.grand-challenge.org/) |
| TCGA-BRCA | 1,098 | 4 | Molecular Subtyping | [Link](https://portal.gdc.cancer.gov/) |
| BRACS | 547 | 7 | Tumor Typing | [Link](https://www.bracs.icar.cnr.it/) |



## Acknowledgments

- [Mamba](https://github.com/state-spaces/mamba) for the State Space Model implementation
- [VMamba](https://github.com/MzeroMiko/VMamba) for 2D scanning patterns
- [CLAM](https://github.com/mahmoodlab/CLAM) for WSI preprocessing pipeline

## Contact

- Sina Mansouri - Smansou3@gmu.edu
- Neelesh Prakash Wadhwani - nwadhwan@gmu.edu
- Philip Stavrev - pstavrev@gmu.edu
